{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 6: Creating and Connecting to Databases\n",
    "## DS 6001\n",
    "\n",
    "### Instructions\n",
    "Please answer the following questions as completely as possible using text, code, and the results of code as needed. Format your answers in a Jupyter notebook. To receive full credit, make sure you address every part of the problem, and make sure your document is formatted in a clean and professional way.\n",
    "\n",
    "**Please note: you will not be able to use Rivanna for this lab as Rivanna is not set up to work with Docker or with Databases. Problem 1 will guide you through the steps to get databases running on your local system. This can be tricky, so if you have questions or would like some help, please let me know.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 0\n",
    "Import the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import sqlite3\n",
    "import psycopg\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import pymongo\n",
    "from bson.json_util import loads, dumps\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "Many database systems run as external software on a computer. Some of the software is commercial (Oracle, Microsoft SQL Server), with limited free use and expensive enterprise level licenses. Other database software is entirely free and open source (MySQL, Postgres, SQlite, MongoDB). Regardless of whether the software is free or not, databases are notoriously difficult to install and start using. More than other kinds of software, database systems seem to run into many errors that are specific to the operating system of your computer. We used to ask students to install Postgres, MySQL, and Mongo, and it was a nightmare because everyone hit some sort of roadblock and those roadblocks were different for every student.\n",
    "\n",
    "That's just how databases seem to be! Not just for students, but for everyone!\n",
    "\n",
    "A growing standard practice in industry is to use **containers** to deploy database systems. Please read the [discussion of containers in the course textbook],(https://jkropko.github.io/surfing-the-data-pipeline/docker.html) if you haven't yet done so to familiarize yourself with the purpose and uses of containers and Docker.\n",
    "\n",
    "This lab will guide you through the installation steps for the software you need to run database systems on your computer (problem 1), build a relational schema (problem 2), document those databases (problem 3), and connect to them through Python with (fingers crossed) as few problems as possible (problem 4 for relational databases, problem 5 for a NoSQL database).\n",
    "\n",
    "With the exception of SQLite (which operates as a Python package), database systems run as external software that must be installed and run on your computer. To make the installation steps easier, you will need some configuration files that I wrote and saved in a GitHub repository. Open your terminal and then type\n",
    "```\n",
    "git clone https://github.com/jkropko/ds6001databases\n",
    "```\n",
    "If this command works, it will create a new directory within your current folder called \"ds6001databases\".\n",
    "\n",
    "* Check that this folder exists and contains the following files: LICENSE, README.md, compose.yaml, and requirements.txt. (Don't worry if there are a couple extra files.)\n",
    "\n",
    "* To make things easier, save the notebook file you will be using for your Lab 6 work inside the \"ds6001databases\" folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a\n",
    "After cloning the ds6001databases repository, open and examine the file called compose.yaml. Then write answers to the following questions based on your reading of the section on [Docker compose files](https://jkropko.github.io/surfing-the-data-pipeline/docker.html#docker-compose-files) in the textbook:\n",
    "\n",
    "1. How many containers are being launched when we execute this compose.yaml file?\n",
    "\n",
    "2. What does each of the containers do?\n",
    "\n",
    "3. Docker is building these containers from Docker image files that it downloads from a website. On what website are these Docker images stored? (You can provide the general name of this website, no need for the specific URLs)\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 3\n",
    "2. runs a MySQL server, a PostgreSQL server, and a MongoDB server.\n",
    "3. Docker Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "If you haven't yet done so, install Docker Desktop on your computer. Go to https://www.docker.com/products/docker-desktop/ and click on the Download button, making sure the operating system listed matches the operating system of your computer (for Apple users, make sure you get the correct version for your computer's processing chip. Click the Apple icon in the top-left corner of your screen, select \"About This Mac\", and see whether Intel or Apple M1 is listed under Chip).\n",
    "\n",
    "Once Docker Desktop is installed, find the Docker Desktop program on your computer and run it.\n",
    "\n",
    "To confirm that Docker Desktop is running, open a terminal and type `docker version`. Copy-and-paste what you see on the screen into your notebook.\n",
    "\n",
    "If your terminal hangs without displaying anything, that likely means that Docker Desktop is not running or not properly installed. Double check that the Docker Desktop is running. If your terminal is hanging, you can press Control + C to regain access to the command prompt.\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Client:\n",
    " Version:           28.4.0\n",
    " API version:       1.51\n",
    " Go version:        go1.24.7\n",
    " Git commit:        d8eb465\n",
    " Built:             Wed Sep  3 20:56:28 2025\n",
    " OS/Arch:           linux/amd64\n",
    " Context:           default\n",
    "\n",
    "Server: Docker Desktop 4.47.0 (206054)\n",
    " Engine:\n",
    "  Version:          28.4.0\n",
    "  API version:      1.51 (minimum version 1.24)\n",
    "  Go version:       go1.24.7\n",
    "  Git commit:       249d679\n",
    "  Built:            Wed Sep  3 20:57:37 2025\n",
    "  OS/Arch:          linux/amd64\n",
    "  Experimental:     false\n",
    " containerd:\n",
    "  Version:          1.7.27\n",
    "  GitCommit:        05044ec0a9a75232cad458027ca83437aae3f4da\n",
    " runc:\n",
    "  Version:          1.2.5\n",
    "  GitCommit:        v1.2.5-0-g59923ef\n",
    " docker-init:\n",
    "  Version:          0.19.0\n",
    "  GitCommit:        de40ad0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c\n",
    "Inside your \"ds6001databases\" folder, create a file named `.env`. Inside the .env file you need to choose passwords for the MySQL, PostgreSQL, and MongoDB databases, so type\n",
    "```\n",
    "MYSQL_ROOT_PASSWORD=password1\n",
    "POSTGRES_PASSWORD=password2\n",
    "MONGO_INITDB_ROOT_PASSWORD=password3\n",
    "MONGO_INITDB_ROOT_USERNAME=mongo\n",
    "mongo_init_db = mongodb\n",
    "MYSQL_DATABASE=mysql\n",
    "```\n",
    "Change the passwords on the first three lines to whatever you want, but DON'T USE THE @ SYMBOL as that will cause problems. Leave the fourth, fifth, and sixth lines alone, as well as the names of each environmental variable.\n",
    "\n",
    "Then run this line of Python code:\n",
    "```\n",
    "dotenv.load_dotenv()\n",
    "```\n",
    "If the .env file has successfully been created and saved in the correct location, the output of this code will be `True`. If `False`, double check the name and location of your file.\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d\n",
    "In the terminal, make sure you are in the \"ds6001databases\" folder (you can check by typing `pwd`. If not, then use `cd` to navigate to the \"ds6001databases\" folder). Then type\n",
    "```\n",
    "docker compose up\n",
    "```\n",
    "This command launches all of the containers for running each of the database systems. If successful, you will see a long stream of output with messages that begin `ds6001databases-postgres-1`, `ds6001databases-mysql-1`, and `ds6001databases-mongo-1`. Copy and paste below the first six lines of this output. (Apologies for all the scrolling you might have to do!)\n",
    "\n",
    "If you receive an error message or if the terminal hangs without displaying output, you will likely need to double-check that parts a, b, and c can still be completed successfully, and that you are working within the \"ds6001databases\" folder via the terminal.\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[+] Running 35/35\n",
    " ✔ postgres Pulled                                                                                                                   70.4s \n",
    " ✔ mongo Pulled                                                                                                                      89.8s \n",
    " ✔ mysql Pulled                                                                                                                      86.5s \n",
    "[+] Running 7/7\n",
    " ✔ Network ds6001databases_default       Created                                                                                      0.1s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part e\n",
    "To confirm that the databases are running on your system, run the following Python code. \n",
    "```\n",
    "# 1. Load needed environment variables\n",
    "dotenv.load_dotenv()\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "MONGO_INITDB_ROOT_USERNAME = os.getenv('MONGO_INITDB_ROOT_USERNAME')\n",
    "MONGO_INITDB_ROOT_PASSWORD = os.getenv('MONGO_INITDB_ROOT_PASSWORD')\n",
    "MYSQL_ROOT_PASSWORD = os.getenv('MYSQL_ROOT_PASSWORD')\n",
    "\n",
    "# 2. Test MySQL\n",
    "dbserver = mysql.connector.connect(\n",
    "    user='root', \n",
    "    password=MYSQL_ROOT_PASSWORD, \n",
    "    host='localhost',\n",
    "    port='3306',\n",
    "    #auth_plugin='mysql_native_password'\n",
    ")\n",
    "\n",
    "# 3. Test PostgreSQL\n",
    "dbserver = psycopg.connect(\n",
    "    user='postgres', \n",
    "    password=POSTGRES_PASSWORD, \n",
    "    host='localhost',\n",
    "    port = '5432'\n",
    ")\n",
    "dbserver.autocommit = True\n",
    "\n",
    "# 4. Test MongoDB\n",
    "myclient = pymongo.MongoClient(f\"mongodb://{MONGO_INITDB_ROOT_USERNAME}:{MONGO_INITDB_ROOT_PASSWORD}@localhost:27017/\")\n",
    "myclient.list_databases()\n",
    "```\n",
    "\n",
    "If this code runs without error, you will see output that looks something like\n",
    "```\n",
    "<pymongo.synchronous.command_cursor.CommandCursor at 0x177d8b380>\n",
    "```\n",
    "and you are all set for working with these databases using Python.\n",
    "\n",
    "If you do see an error, then you will need to troubleshoot. A few things to try:\n",
    "\n",
    "* Double check that your work for parts a, b, c, and d can still run successfully.\n",
    "\n",
    "* Read the error to determine which of the databases is causing the error, to narrow the problem down. Comment-out or delete this part of the code to see if the other databases are working.\n",
    "\n",
    "* Check the output in the terminal where you issued the `docker compose up` command. Scroll up and down, and look for any lines that write that a container has exited.\n",
    "\n",
    "* Try a reset of the containers by pressing Control+C in the terminal displaying Docker output, then `docker compose down`, then `docker compose up` again. Then try running the Python code again.\n",
    "\n",
    "* Sometimes (especially if you've changed the database passwords at some point) incorrect passwords get saved in the Docker volumes and do not change when you make a change to your .env file. To fix this, press Control+C in the terminal displaying Docker output, then `docker compose down`. Then open the Docker Desktop, click on volumes, and find and delete the volumes associated with the \"ds6001databases\" containers. Then return to the terminal,type `docker compose up`, and try again.\n",
    "\n",
    "* If all else fails, you are far from the only one to hit a roadblock at this stage. Send me or one of the TAs a message and we can help.\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.synchronous.command_cursor.CommandCursor at 0x794a2dcd2e40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load needed environment variables\n",
    "dotenv.load_dotenv()\n",
    "POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "MONGO_INITDB_ROOT_USERNAME = os.getenv('MONGO_INITDB_ROOT_USERNAME')\n",
    "MONGO_INITDB_ROOT_PASSWORD = os.getenv('MONGO_INITDB_ROOT_PASSWORD')\n",
    "MYSQL_ROOT_PASSWORD = os.getenv('MYSQL_ROOT_PASSWORD')\n",
    "\n",
    "# 2. Test MySQL\n",
    "dbserver = mysql.connector.connect(\n",
    "    user='root', \n",
    "    password=MYSQL_ROOT_PASSWORD, \n",
    "    host='localhost',\n",
    "    port='3306',\n",
    "    #auth_plugin='mysql_native_password'\n",
    ")\n",
    "\n",
    "# 3. Test PostgreSQL\n",
    "dbserver = psycopg.connect(\n",
    "    user='postgres', \n",
    "    password=POSTGRES_PASSWORD, \n",
    "    host='localhost',\n",
    "    port = '5432'\n",
    ")\n",
    "dbserver.autocommit = True\n",
    "\n",
    "# 4. Test MongoDB\n",
    "myclient = pymongo.MongoClient(f\"mongodb://{MONGO_INITDB_ROOT_USERNAME}:{MONGO_INITDB_ROOT_PASSWORD}@localhost:27017/\")\n",
    "myclient.list_databases()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 \n",
    "For this problem, I created fake data that represents patients who saw a doctor and received one or more prescriptions. Your goal in this problem is to reorganize the data into a database schema that conforms to E. F. Codd's 3rd normal form, and to document the resulting relational database using an ER diagram.\n",
    "\n",
    "Wrapping your head around the normal form rules and building and documenting a database schema can be very difficult. First, grant yourself a lot of grace and give yourself plenty of time to take on this problem. Mastering database schema and documentation are central skills that distinguish a data engineer from a data scientist or analyst, so it is worth taking time to think about this task.\n",
    "\n",
    "The data are listed on the following Google sheet: https://docs.google.com/spreadsheets/d/11wUk5dg39lmI-_O0SQ0M5_5VGgzuGJKvSyMq4Tyxc9M/edit?usp=sharing. For this problem you will be manipulating the data. I only included 10 rows to enable you to use any method you like for working with the data, including point-and-click data manipulation on Google sheets or Excel. Or you can use `pandas` if you like. We are emphasizing the product over the process for now. \n",
    "\n",
    "There are two tabs on this spreadsheet. The first tab contains the data and the second tab contains column descriptions and notes. These notes (some of which are unrealistic, but needed for this exercise) are:\n",
    "\n",
    "* No two patients have the same name and date of birth, so `patient_name` and `date_of_birth` together uniquely identify a patient.\n",
    "\n",
    "* No two drugs share the same brand name, so `prescribed_drug` uniquely identifies the drug.\n",
    "\n",
    "* The data contain one row for every patient/prescription combination, and no patient receives more than one prescription for the same drug. So `patient_name`, `date_of_birth`, and `prescribed_drug` comprise a primary key in the original data.\n",
    "\n",
    "* No two physicians in the data share the same name, so `prescribing_physician` uniquely identifies physicians.\n",
    "\n",
    "* Patients do not change their insurance provider.\n",
    "\n",
    "* Every physician works at exactly one hospital, no two hospitals share the same name, and every hospital exists at exactly one location.\n",
    "\n",
    "Some things to keep in mind for this problem:\n",
    "\n",
    "1. Remember that the first rule for 2nd normal form is that the data are in 1st normal form, and the first rule for 3rd normal form is that the data are already in 2nd normal form. So please focus on meeting the rules for 1st, then 2nd, then 3rd normal form *in that order*. \n",
    "\n",
    "2. Some students have never worked with databases before, but some have. If you have seen databases before, you have some ideas about how database schema tend to look. But if you arrange the data to match an idea of how databases often look, you will more than likely over-engineer the database by creating too many tables or unnecessary columns. Instead, focus on the explicit rules for each normal form and stop once those rules are met. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Part a\n",
    "In words, address the following points regarding 1st normal form:\n",
    "\n",
    "* Describe the problem or problems that exist in the original data that prevent it from meeting the requirements for 1st normal form. \n",
    "\n",
    "* Describe a reorganization of the data that does conform to 1st normal form. If this schema has multiple tables, give each table a name that indicates what the rows in the table represent. List the columns that exist in each table, and if the number of rows in a table is different from the number of rows in the original data, explain why. \n",
    "\n",
    "(It will help you to make these edits to the data now, but you won't show your final data until part d)\n",
    "\n",
    "[8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"prior_conditions\" and \"hospital_location\" field has multiple values, which breaks the atomic requirement. We also need to identify primary keys, which in our case should be the combination of \"patient_name\", \"date_of_birth\", and \"prescribed_drug\".\n",
    "\n",
    "For reorganization, we should first seperate the city and state from \"hospital_location\" into two seperate columns. Secondly, we could create a seperate Table called \"Patient Conditions\" and host \"prior_conditions\" there, then drop the column from the main table.\n",
    "\n",
    "Patient Prescriptions: patient_name, date_of_birth, prescribed_drug, patient_sex, patient_insurance, drug_maker, drug_cost, prescribing_physician, physician_medschool, physician_years_experience, hospital, hospital_city, hospital_state.\n",
    "\n",
    "Patient Conditions: patient_name, date_of_birth, condition_name.\n",
    "\n",
    "Number of rows should stay the same for the main table. For the Patient Conditions table, there should be the same number of rows as there are unique combinations of conditions and patients. For our case there should be 11 rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "In words, address the following points regarding 2nd normal form:\n",
    "\n",
    "* Describe the problem or problems that exist in the 1st normal form data that prevent it from meeting the requirements for 2nd normal form. \n",
    "\n",
    "* Describe a reorganization of the data that does conform to 2nd normal form. If this schema has multiple tables, give each table a name that connects to what the rows in the table represent. List the columns that exist in each table, and if the number of rows in a table is different from the number of rows in the original data, explain why. \n",
    "\n",
    "(It will help you to make these edits to the data now, but you won't show your final data until part d)\n",
    "\n",
    "[8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the patient attributes, \"patient_sex\" and \"patient_insurance\", only depend on \"patient_name\" and \"date_of_birth\". \"drug_maker\" and \"drug_cost\" only depend on \"prescribed_drug\". \n",
    "\n",
    "To solve this we can make a seperate table with all the patient attributes, patient_name, date_of_birth, patient_sex, and patient_insurance, to represent patient data, and drop patient_sex and patient_insurance from the Patient Prescriptions table. Same with drug_maker and drug_cost. We can make a seperate table with prescribed_drug, drug_maker, and drug_cost to represent drug data. Then remove drug_maker and drug_cost from the main table.\n",
    "\n",
    "Patient Prescriptions: patient_name, date_of_birth, prescribed_drug, prescribing_physician, physician_medschool, physician_years_experience, hospital, hospital_city, hospital_state.\n",
    "\n",
    "Patient Conditions: patient_name, date_of_birth, condition_name.\n",
    "\n",
    "Patients Table: patient_name, date_of_birth, patient_sex, patient_insurance.\n",
    "\n",
    "Drug Table: prescribed_drug, drug_maker, drug_cost.\n",
    "\n",
    "Number of rows should stay the same for the main table and Patient Conditions table, while Patients Info table should have as many rows as there are unique patients (4). Same with the Drug Info Table, it will have as many rows as there are unique drugs (10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c\n",
    "In words, address the following points regarding 3rd normal form:\n",
    "\n",
    "* Describe the problem or problems that exist in the 2nd normal form data that prevent it from meeting the requirements for 3rd normal form. \n",
    "\n",
    "* Describe a reorganization of the data that does conform to 3rd normal form. If this schema has multiple tables, give each table a name that connects to what the rows in the table represent. List the columns that exist in each table, and if the number of rows in a table is different from the number of rows in the original data, explain why. \n",
    "\n",
    "(It will help you to make these edits to the data now, but you won't show your final data until part d)\n",
    "\n",
    "[8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "physician_medschool and physician_years_experience both depend only on prescribing_physician, which is not a primary key. Same with hospital_city and hospital_state, as they only depend on hospital.\n",
    "\n",
    "To solve this we should create a seperate table with all the mentioned physician attribute columns, and remove all except for prescribing_physician from the main table. Same with hospital, make a seperate table, then remove city and state from the main table.\n",
    "\n",
    "Patient Prescriptions(same number of rows): patient_name, date_of_birth, prescribed_drug, prescribing_physician, hospital.\n",
    "\n",
    "Patient Conditions(10 rows): patient_name, date_of_birth, condition_name.\n",
    "\n",
    "Patients(4 rows): patient_name, date_of_birth, patient_sex, patient_insurance.\n",
    "\n",
    "Drugs(10 rows): prescribed_drug, drug_maker, drug_cost.\n",
    "\n",
    "Physicians(5 rows): prescribing_physician, physician_medschool, physician_years_experience, hospital.\n",
    "\n",
    "Hospitals(4 rows): hospital, hospital_city, hospital_state.\n",
    "\n",
    "The newly added Physicians and Hospitals Table has different number of rows than the original data because there are only 5 unique physicians and 4 unique hospitals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d\n",
    "Display all of the tables in their entirety from the version of the data you designed for part (c) to meet the requirements of 3rd normal form. \n",
    "\n",
    "You can use several different methods to display these tables. You can download the tables to CSV format then upload them into your notebook using `pd.read_csv()`, or you can represent them using Markdown table syntax using a tool such as  https://www.tablesgenerator.com/markdown_tables, or you can include them as screenshot images if you want. (Please don't just provide external links however, as that will slow down our grading)\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patient Prescriptions:\n",
    "| patient_name       | date_of_birth | prescribed_drug | prescribing_physician | hospital                       |\n",
    "|--------------------|---------------|-----------------|-----------------------|--------------------------------|\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Amoxil          | Earnest Caro          | UPMC Presbyterian Shadyside    |\n",
    "| Nkemdilim Arendonk | 2/21/1962     | Micronase       | Earnest Caro          | UPMC Presbyterian Shadyside    |\n",
    "| Raniero Coumans    | 8/15/1990     | Zosyn           | Pamela English        | Northwestern Memorial Hospital |\n",
    "| Raniero Coumans    | 8/15/1990     | Humira          | Samantha Bergerson    | Northwestern Memorial Hospital |\n",
    "| Mizuki Debenham    | 3/12/1977     | Inlyta          | Lewis Conti           | Houston Methodist Hospital     |\n",
    "| Zoë De Witt        | 11/23/1947    | Atenolol        | Theresa Dahlmans      | Mount Sinai Hospital           |\n",
    "| Zoë De Witt        | 11/23/1947    | Micronase       | Hilde Ali             | Mount Sinai Hospital           |\n",
    "| Zoë De Witt        | 11/23/1947    | Demerol         | Hilde Ali             | Mount Sinai Hospital           |\n",
    "| Bonnie Hooper      | 7/4/1951      | Xeloda          | Steven Garbutt        | UCSF Medical Center            |\n",
    "| Bonnie Hooper      | 7/4/1951      | Demerol         | Steven Garbutt        | UCSF Medical Center            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patient Conditions:\n",
    "| patient_name | date_of_birth |  condition_name  |\n",
    "|:------------:|:-------------:|:----------------:|\n",
    "| Zoe De Witt  |    1978-05-14 | Cardiomyopathy   |\n",
    "| Zoe De Witt  |    1978-05-14 | Diabetes         |\n",
    "| Zoe De Witt  |    1978-05-14 | Sciatica         |\n",
    "| Zoe De Witt  |    1978-05-14 | Shingles         |\n",
    "| Alex Johnson |    1984-02-09 | Hypertension     |\n",
    "| Alex Johnson |    1984-02-09 | Sleep Apnea      |\n",
    "| Mei Lin      |    1990-07-30 | Asthma           |\n",
    "| Mei Lin      |    1990-07-30 | Depression       |\n",
    "| Peter Novak  |    1975-12-03 | GERD             |\n",
    "| Peter Novak  |    1975-12-03 | High Cholesterol |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patients:\n",
    "| patient_name | date_of_birth | patient_sex | patient_insurance |\n",
    "|:------------:|:-------------:|:-----------:|:-----------------:|\n",
    "| Zoe De Witt  |     5/14/1978 | F           | Blue Cross        |\n",
    "| Alex Johnson |      2/9/1984 | M           | United Health     |\n",
    "| Mei Lin      |     7/30/1990 | F           | Aetna             |\n",
    "| Peter Novak  |     12/3/1975 | M           | Cigna             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drugs:\n",
    "| prescribed_drug | drug_maker               | drug_cost |\n",
    "|-----------------|--------------------------|-----------|\n",
    "| Amoxil          | USAntibiotics            |     14.62 |\n",
    "| Micronase       | Pfizer                   |     20.55 |\n",
    "| Zosyn           | Baxter International Inc |       394 |\n",
    "| Humira          | Abbvie                   |      7000 |\n",
    "| Inlyta          | Pfizer                   |     21644 |\n",
    "| Atenolol        | Mylan Pharmaceuticals    |     10.58 |\n",
    "| Micronase       | Pfizer                   |     20.55 |\n",
    "| Demerol         | Pfizer                   |      37.5 |\n",
    "| Xeloda          | Genentech                |       860 |\n",
    "| Demerol         | Pfizer                   |      37.5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physicians:\n",
    "| prescribing_physician | physician_medschool | physician_years_experience |     hospital     |\n",
    "|:---------------------:|:-------------------:|:--------------------------:|:----------------:|\n",
    "| John Smith            | Harvard             |                         15 | Mercy General    |\n",
    "| Sarah Lee             | Yale                |                          8 | Mercy General    |\n",
    "| Mark Evans            | Johns Hopkins       |                         12 | St. Luke’s       |\n",
    "| Sara Patel            | Columbia            |                          9 | New York Medical |\n",
    "| Daniel Chen           | Northwestern        |                         10 | Chicago General  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hospitals:\n",
    "|     hospital     | hospital_city | hospital_state |\n",
    "|:----------------:|:-------------:|:--------------:|\n",
    "| Mercy General    | Pittsburgh    | PA             |\n",
    "| St. Luke’s       | Baltimore     | MD             |\n",
    "| New York Medical | New York      | NY             |\n",
    "| Chicago General  | Chicago       | IL             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "For this problem, you will be documenting and a building database that contains the entire collected works of Shakespeare.\n",
    "\n",
    "<img src=\"https://image.cagle.com/178551/750/178551.png\" width=\"300\" alt='Shakespeare Twitter comic'>\n",
    "\n",
    "The data were collected by [Catherine Devlin](https://github.com/catherinedevlin/opensourceshakespeare) for https://opensourceshakespeare.org/. The database will have five tables, and they will be brought into your Python environment as `pandas` dataframes in 3rd normal form  by running this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'https://github.com/jkropko/DS-6001/raw/master/localdata/'\n",
    "works = pd.read_csv(repo + 'Works.csv')\n",
    "characters = pd.read_csv(repo + 'Characters.csv')\n",
    "chapters = pd.read_csv(repo + 'Chapters.csv')\n",
    "paragraphs = pd.read_csv(repo + 'Paragraphs.csv')\n",
    "\n",
    "# convert column names to lowercase (needed for postgreSQL to work properly)\n",
    "characters.columns = characters.columns.str.lower() \n",
    "chapters.columns = chapters.columns.str.lower()\n",
    "paragraphs.columns = paragraphs.columns.str.lower()\n",
    "works.columns = works.columns.str.lower()\n",
    "\n",
    "# works in the characters tables is a comma separated list. \n",
    "# Break it out into multiple rows in a new table\n",
    "charworks = characters[['charid', 'works']]\n",
    "charworks.loc[:,'works'] = charworks['works'].str.split(',')\n",
    "charworks = charworks.explode('works')\n",
    "charworks = charworks.rename({'works':'workid'}, axis=1)\n",
    "characters = characters.drop('works', axis=1)\n",
    "\n",
    "#Remove empty rows\n",
    "chapters = chapters.query(\"~chapterid.isnull()\")\n",
    "paragraphs = paragraphs.query(\"~paragraphid.isnull()\")\n",
    "charworks = charworks.query(\"~workid.isnull()\")\n",
    "\n",
    "# Add chapterid to paragraphs\n",
    "paragraphs = pd.merge(paragraphs, \n",
    "                      chapters.drop('description', axis=1),\n",
    "                      how='inner', \n",
    "                      on=['workid', 'section', 'chapter'])\n",
    "\n",
    "#Remove unnecessary columns\n",
    "paragraphs = paragraphs.drop(['paragraphtype', 'section', 'chapter'], \n",
    "                             axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The five tables are:\n",
    "\n",
    "**works**: One row per work authored by Shakespeare, with columns:\n",
    "* `workid`: (primary key) a unique ID without spaces or special characters for the work\n",
    "* `title`: the title, such as \"Twelfth Night\"\n",
    "* `longtitle`: a longer title, if there is one, such as \"Twelfth Night, Or What You Will\"\n",
    "* `date`: year of publication\n",
    "* `genretype`: `t` is a tragedy, such as *Romeo and Juliet* and *Hamlet*; `c` is a comedy, such as *A Midsummer Night's Dream* and *As You Like It*; `h` is a history, such as *Henry V* and *Richard III*; `s` refers to Shakespeare's sonnets; `p` is a narrative (non-sonnet) poem, such as *Venus and Adonis* and *Passionate Pilgrim*\n",
    "* `notes`: Column for notes from the database maintainer, currently all `NaN`\n",
    "* `source`: whether the text was originally downloaded from the [Moby Project lexicon](https://en.wikipedia.org/wiki/Moby_Project) or [Project Gutenberg](https://www.gutenberg.org/). \n",
    "* `totalwords`: Total words in the work\n",
    "* `totalparagraphs`: Total number of lines of dialogue for plays, or stanzas for poems\n",
    "\n",
    "**characters**: One row per character that appears in at least one work by Shakespeare. Some characters, such as Antony or Henry IV, appear in multiple works. Columns:\n",
    "* `charid`: (primary key) a unique ID for a character\n",
    "* `charname`: character's name (some characters are different but have the same name, such as the First Musician in Othello and the First Musician in Romeo and Juliet). For poems, the character is \"Poet\" \n",
    "* `abbrev`: an abbreviation of the character's name, if needed for reference to some other analyses\n",
    "* `description`: a longer description of who the character is, if available\n",
    "* `speechcount`: number of lines of dialogue delivered by the character throughout the works the character appears in\n",
    "\n",
    "**chapters**: One row for every unique scene in a play, or for every distinct poem in a collection of poems. Columns:\n",
    "* `workid`: a unique ID without spaces or special characters for the work\n",
    "* `chapterid`: (primary key) a unique ID for the scene/poem\n",
    "* `section`: the scene/poem number\n",
    "* `chapter`: the act number, if available\n",
    "* `description`: short description of where the scene takes place, for plays\n",
    "\n",
    "**paragraphs**: One row for every line of dialogue that appears in a Shakespeare play, or for every distinct poem in a collection of poems. Columns:\n",
    "* `workid`: a unique ID without spaces or special characters for the work\n",
    "* `paragraphid`: (primary key) a unique ID for the line of dialogue/poem\n",
    "* `paragraphnum`: the position of the paragraph within the ordered list of paragraphs within a chapter\n",
    "* `charid`: the unique ID of the character delivering the line of dialogue/poem\n",
    "* `plaintext`: the text of the dialogue/poem\n",
    "* `phonetictext`: the text of the dialogue/poem in phonetic text, useful for training computers to generate audio of this spoken text\n",
    "* `stemtext`: the stems of the words in the text, useful for text analyses such as sentiment analysis\n",
    "* `charcount`: number of characters in the line\n",
    "* `wordcount`: number of words in the line\n",
    "* `chapterid`: unique ID for the scene/poem\n",
    "\n",
    "**charworks**: One row for every unique combination of character and play. Most characters appear once, but some (such as Antony or Henry IV) appear multiple times. Columns\n",
    "* `charid`: (primary key) unique ID for the character\n",
    "* `workid`: (primary key) unique ID for the work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a\n",
    "\n",
    "Please refer to the [textbook's discussion of ER diagrams](https://jkropko.github.io/surfing-the-data-pipeline/ch6.html#entity-relationship-diagrams) as you complete this problem.\n",
    "\n",
    "For each of the following pairs of tables, write\n",
    "1. Which column or columns the tables should be joined on\n",
    "2. A description of your reasoning, in plain language, for whether each table matches to one or many rows in the other\n",
    "3. Whether there is a one-to-one, one-to-many, many-to-one, or many-to-many relationship between the tables\n",
    "4. Write the database markup language (DBML) code to represent this kind of a relationship. \n",
    "\n",
    "If we are connecting two tables named `table_a` and `table_b` on a column named `joincolumn` in each table, then the DBML syntax is \n",
    "\n",
    "* `Ref: table_a.joincolumn - table_b.joincolumn` if the relationship from `table_a` to `table_b` is one-to-one\n",
    "\n",
    "* `Ref: table_a.joincolumn < table_b.joincolumn` if the relationship from `table_a` to `table_b` is one-to-many\n",
    "\n",
    "* `Ref: table_a.joincolumn > table_b.joincolumn` if the relationship from `table_a` to `table_b` is many-to-one\n",
    "\n",
    "* `Ref: table_a.joincolumn <> table_b.joincolumn` if the relationship from `table_a` to `table_b` is many-to-many\n",
    "\n",
    "If there are multiple columns that must be joined on, provide the DBML code for each of these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a, problem i\n",
    "**charworks** and **works** [2 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on: charworks.workid = works.workid\n",
    "\n",
    "Reasoning: Each row in charworks represents a character–work pair. Every such pair belongs to exactly one work, but each work includes many such rows (since it has many characters).\n",
    "\n",
    "Relationship type: one-to-many, one works record to many charworks records.\n",
    "\n",
    "DBML: Ref: works.workid < charworks.workid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a, problem ii\n",
    "**characters** and **charworks** [2 points]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on: characters.charid = charworks.charid\n",
    "\n",
    "Reasoning: Each character can appear in multiple works (“Antony” appears in more than one play), but each charworks entry belongs to one character.\n",
    "\n",
    "Relationship type: one-to-many, one characters record to many charworks records.\n",
    "\n",
    "DBML: Ref: characters.charid < charworks.charid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a, problem iii\n",
    "**works** and **paragraphs** [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on: works.workid = paragraphs.workid\n",
    "\n",
    "Reasoning: Each paragraph (a line of text) belongs to a single work, while a work can contain thousands of paragraphs.\n",
    "\n",
    "Relationship type: one-to-many, one works record to many paragraphs records.\n",
    "\n",
    "DBML: Ref: works.workid < paragraphs.workid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a, problem iv\n",
    "**chapters** and **works** [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on: works.workid = chapters.workid\n",
    "\n",
    "Reasoning: Each work contains multiple chapters (scenes/poems), and every chapter belongs to exactly one work.\n",
    "\n",
    "Relationship type: one-to-many, one works record to many chapters records.\n",
    "\n",
    "DBML: Ref: works.workid < chapters.workid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a, problem v\n",
    "**paragraphs** and **chapters** [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on: chapters.chapterid = paragraphs.chapterid\n",
    "\n",
    "Reasoning: Each scene/poem (chapter) has many paragraphs (lines of text), and each paragraph belongs to one chapter.\n",
    "\n",
    "Relationship type: one-to-many, one chapters record to many paragraphs records.\n",
    "\n",
    "DBML: Ref: chapters.chapterid < paragraphs.chapterid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part a, problem vi\n",
    "**characters** and **paragraphs** (count groups that might say a line in unison, like Chorus or Witches, as one character) [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join on: characters.charid = paragraphs.charid\n",
    "\n",
    "Reasoning: A single character can have many lines of dialogue across works, but each line of dialogue (paragraph) is spoken by only one character (even if that “character” is a group like Chorus).\n",
    "\n",
    "Relationship type: one-to-many, one characters record to many paragraphs records.\n",
    "\n",
    "DBML: Ref: characters.charid < paragraphs.charid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "\n",
    "Please find the \"Using dbdiagram.io and dbdocs.io to Document Your Database\" page on Canvas. It is available under Modules and \"Getting Started with the Tools We'll Be Using\". Read the page and watch the video about using dbdocs.io and dbdiagram.io to document a relational database with an ER diagram.\n",
    "\n",
    "Use https://dbdiagram.io to create an ER diagram for the five Shakespeare data tables, then publish this diagram to a stable URL by pressing the \"Publish to dbdocs\" button. Paste a link here to your ER diagram on DBdocs.io. Then paste your DBML code from dbdiagrams.io into the box below.\n",
    "\n",
    "A few notes:\n",
    "\n",
    "You can use the `pandas_df_to_dbml()` function, defined below, to generate database markup language (DBML) code for each table that also lists each column's data type, then paste this code into dbdiagram.io (use `print()` around the output to see the correct formatting):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_df_to_dbml(df: pd.DataFrame, table_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a pandas DataFrame to a DBML string.\n",
    "\n",
    "    Args:\n",
    "        df: The pandas DataFrame to convert.\n",
    "        table_name: The name of the table in the DBML schema.\n",
    "\n",
    "    Returns:\n",
    "        A DBML string representing the DataFrame schema.\n",
    "    \"\"\"\n",
    "\n",
    "    dbml_string = f\"Table {table_name} {{\\n\"\n",
    "\n",
    "    for column_name, column_type in df.dtypes.items():\n",
    "        dbml_type = map_pandas_dtype_to_dbml_type(column_type)\n",
    "        dbml_string += f\"  {column_name} {dbml_type}\\n\"\n",
    "\n",
    "    dbml_string += \"}\\n\"\n",
    "    return dbml_string\n",
    "\n",
    "def map_pandas_dtype_to_dbml_type(dtype) -> str:\n",
    "    \"\"\"Maps a pandas dtype to a DBML type.\"\"\"\n",
    "    dtype_name = str(dtype)\n",
    "    if \"int\" in dtype_name:\n",
    "      return \"int\"\n",
    "    if \"float\" in dtype_name:\n",
    "      return \"float\"\n",
    "    if \"datetime\" in dtype_name:\n",
    "        return \"datetime\"\n",
    "    return \"varchar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table works {\n",
      "  workid varchar\n",
      "  title varchar\n",
      "  longtitle varchar\n",
      "  date int\n",
      "  genretype varchar\n",
      "  notes float\n",
      "  source varchar\n",
      "  totalwords int\n",
      "  totalparagraphs int\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pandas_df_to_dbml(works, \"works\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table characters {\n",
      "  charid varchar\n",
      "  charname varchar\n",
      "  abbrev varchar\n",
      "  description varchar\n",
      "  speechcount float\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pandas_df_to_dbml(characters, \"characters\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table chapters {\n",
      "  workid varchar\n",
      "  chapterid float\n",
      "  section float\n",
      "  chapter float\n",
      "  description varchar\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pandas_df_to_dbml(chapters, \"chapters\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table paragraphs {\n",
      "  workid varchar\n",
      "  paragraphid varchar\n",
      "  paragraphnum varchar\n",
      "  charid varchar\n",
      "  plaintext varchar\n",
      "  phonetictext varchar\n",
      "  stemtext varchar\n",
      "  charcount float\n",
      "  wordcount float\n",
      "  chapterid float\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pandas_df_to_dbml(paragraphs, \"paragraphs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table charworks {\n",
      "  charid varchar\n",
      "  workid varchar\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pandas_df_to_dbml(charworks, \"charworks\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the syntax [pk] after a column name and data type to designate the columns that are primary keys in each table. In this case the primary keys are \n",
    "\n",
    "| Table      | Primary Key column(s) |\n",
    "|------------|-----------------------|\n",
    "| works      | workid                |\n",
    "| characters | charid                |\n",
    "| paragraphs | paragraphid           |\n",
    "| chapters   | chapterid             |\n",
    "| charworks  | charid, workid        |\n",
    "\n",
    "To draw the lines linking one table to another, include the `Ref:` syntax that you wrote for your answers to part (a).\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "// Use DBML to define your database structure\n",
    "// Docs: https://dbml.dbdiagram.io/docs\n",
    "\n",
    "Table works {\n",
    "  workid varchar [pk]\n",
    "  title varchar\n",
    "  longtitle varchar\n",
    "  date int\n",
    "  genretype varchar\n",
    "  notes float\n",
    "  source varchar\n",
    "  totalwords int\n",
    "  totalparagraphs int\n",
    "}\n",
    "\n",
    "Table characters {\n",
    "  charid varchar [pk]\n",
    "  charname varchar\n",
    "  abbrev varchar\n",
    "  description varchar\n",
    "  speechcount float\n",
    "}\n",
    "\n",
    "Table chapters {\n",
    "  workid varchar\n",
    "  chapterid float [pk]\n",
    "  section float\n",
    "  chapter float\n",
    "  description varchar\n",
    "}\n",
    "\n",
    "Table paragraphs {\n",
    "  workid varchar\n",
    "  paragraphid varchar [pk]\n",
    "  paragraphnum varchar\n",
    "  charid varchar\n",
    "  plaintext varchar\n",
    "  phonetictext varchar\n",
    "  stemtext varchar\n",
    "  charcount float\n",
    "  wordcount float\n",
    "  chapterid float\n",
    "}\n",
    "\n",
    "Table charworks {\n",
    "  charid varchar [pk]\n",
    "  workid varchar [pk]\n",
    "}\n",
    "\n",
    "Ref: works.workid < charworks.workid\n",
    "Ref: characters.charid < charworks.charid\n",
    "Ref: works.workid < paragraphs.workid\n",
    "Ref: works.workid < chapters.workid\n",
    "Ref: chapters.chapterid < paragraphs.chapterid\n",
    "Ref: characters.charid < paragraphs.charid\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "For this problem, you will use the five dataframes that comprise the Shakespeare database you used in problem 3 to initialize local databases using SQlite, MySQL, and PostgreSQL. \n",
    "\n",
    "All of the methods for initializing and connecting to databases in Python are listed in the [textbook](https://jkropko.github.io/surfing-the-data-pipeline/ch6.html#working-with-databases-in-python). Note that there are differences in code that depend on whether you are using SQlite, MySQL, or PostgreSQL. \n",
    "\n",
    "For creating databases on the MySQL and PostgreSQL servers, you will connect directly to the database server and use the `.cursor()` method to interact with it. But once the database exists, please use the `pd.to_sql()` and `pd.read_sql_query()` methods from `pandas` and the `create_engine()` method from `sqlalchemy` (and not the `.cursor()` approach) to add data to or retrieve data from the database. \n",
    "\n",
    "Before attempting this problem, please make sure your work for problem 1 runs without error, which will ensure your docker containers for MySQL and PostgreSQL are ready to use (SQlite does not require external software and can run without Docker)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a\n",
    "Initialize a new Shakespeare database using SQlite via the `sqlite3` package. Next use the `pd.to_sql()` method to add the five Shakespeare dataframes to this database. Then, to prove that this worked, issue the following SQL query to the database which should display a dataframe listing all characters from Shakespeare's plays with more than 200 lines of dialogue (and the Poet too):\n",
    "```\n",
    "SELECT charname, description, speechcount\n",
    "FROM characters\n",
    "WHERE speechcount > 200\n",
    "```\n",
    "Finally, after running the query, use the `.commit()` and `.close()` methods on the Python variable containing the database connection to save your changes and prevent further changes.\n",
    "\n",
    "[8 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1346"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssdb = sqlite3.connect(\"shakespeare.db\")\n",
    "\n",
    "works.to_sql(\"works\", ssdb,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "characters.to_sql(\"characters\", ssdb,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "chapters.to_sql(\"chapters\", ssdb,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "paragraphs.to_sql(\"paragraphs\", ssdb,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "charworks.to_sql(\"charworks\", ssdb,  index=False, chunksize=1000, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charname</th>\n",
       "      <th>description</th>\n",
       "      <th>speechcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antony</td>\n",
       "      <td>(Marcus Antonius)</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>queen of Egypt</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Falstaff</td>\n",
       "      <td>Sir John Falstaff</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Duke of Gloucester</td>\n",
       "      <td>brother to the King</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamlet</td>\n",
       "      <td>son of the former king and nephew to the prese...</td>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Henry V</td>\n",
       "      <td>Prince, King of England</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iago</td>\n",
       "      <td>Othello's ancient (?)</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Othello</td>\n",
       "      <td>A noble Moor in the service of the Ventian state</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Poet</td>\n",
       "      <td>the voice of Shakespeare's poetry</td>\n",
       "      <td>733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Richard III</td>\n",
       "      <td>son of Richard Plantagenet, duke of York; was ...</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             charname                                        description  \\\n",
       "0              Antony                                  (Marcus Antonius)   \n",
       "1           Cleopatra                                     queen of Egypt   \n",
       "2            Falstaff                                  Sir John Falstaff   \n",
       "3  Duke of Gloucester                                brother to the King   \n",
       "4              Hamlet  son of the former king and nephew to the prese...   \n",
       "5             Henry V                            Prince, King of England   \n",
       "6                Iago                              Othello's ancient (?)   \n",
       "7             Othello   A noble Moor in the service of the Ventian state   \n",
       "8                Poet                  the voice of Shakespeare's poetry   \n",
       "9         Richard III  son of Richard Plantagenet, duke of York; was ...   \n",
       "\n",
       "   speechcount  \n",
       "0        253.0  \n",
       "1        204.0  \n",
       "2        471.0  \n",
       "3        285.0  \n",
       "4        358.0  \n",
       "5        377.0  \n",
       "6        272.0  \n",
       "7        274.0  \n",
       "8        733.0  \n",
       "9        246.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myquery  = \"\"\"\n",
    "SELECT charname, description, speechcount\n",
    "FROM characters\n",
    "WHERE speechcount > 200\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(myquery, ssdb)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssdb.commit()\n",
    "ssdb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Use the `dotenv` package to import your MySQL database password into your Python environment (don't expose this password in your code). Then use this password to initialize a new Shakespeare database using MySQL and the `mysql.connector` package. \n",
    "\n",
    "Next, use the `create_engine()` method from `sqlalchemy` and the `pd.to_sql()` method to add the five Shakespeare dataframes to this database. Then, to prove that this worked, use the `pd.read_sql_query()` method to issue the following SQL query to the database\n",
    "```\n",
    "SELECT charname, description, speechcount\n",
    "FROM characters\n",
    "WHERE speechcount > 200\n",
    "```\n",
    "Finally, after running the query, use the `.commit()` and `.close()` methods on the Python variable containing the database connection to save your changes and prevent further changes.\n",
    "\n",
    "[8 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbserver = mysql.connector.connect(\n",
    "    user='root',\n",
    "    password=MYSQL_ROOT_PASSWORD,\n",
    "    host='localhost',\n",
    "    port='3306')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = dbserver.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"CREATE DATABASE shakespeare\")\n",
    "except:\n",
    "    cursor.execute(\"DROP DATABASE shakespeare\")\n",
    "    cursor.execute(\"CREATE DATABASE shakespeare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('information_schema',),\n",
       " ('mysql',),\n",
       " ('performance_schema',),\n",
       " ('shakespeare',),\n",
       " ('sys',)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"SHOW DATABASES\")\n",
    "databases = cursor.fetchall()\n",
    "databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(mysql+mysqlconnector://root:***@localhost:3306/shakespeare)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbms = 'mysql'\n",
    "package = 'mysqlconnector'\n",
    "user = 'root'\n",
    "password = MYSQL_ROOT_PASSWORD\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "db = 'shakespeare'\n",
    "\n",
    "engine = create_engine(f\"{dbms}+{package}://{user}:{password}@{host}:{port}/{db}\")\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1346"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "works.to_sql(\"works\", con = engine,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "characters.to_sql(\"characters\", con = engine,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "chapters.to_sql(\"chapters\", con = engine,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "paragraphs.to_sql(\"paragraphs\", con = engine,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "charworks.to_sql(\"charworks\", con = engine,  index=False, chunksize=1000, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charname</th>\n",
       "      <th>description</th>\n",
       "      <th>speechcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antony</td>\n",
       "      <td>(Marcus Antonius)</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>queen of Egypt</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Falstaff</td>\n",
       "      <td>Sir John Falstaff</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Duke of Gloucester</td>\n",
       "      <td>brother to the King</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamlet</td>\n",
       "      <td>son of the former king and nephew to the prese...</td>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Henry V</td>\n",
       "      <td>Prince, King of England</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iago</td>\n",
       "      <td>Othello's ancient (?)</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Othello</td>\n",
       "      <td>A noble Moor in the service of the Ventian state</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Poet</td>\n",
       "      <td>the voice of Shakespeare's poetry</td>\n",
       "      <td>733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Richard III</td>\n",
       "      <td>son of Richard Plantagenet, duke of York; was ...</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rosalind</td>\n",
       "      <td>daughter to the banished Duke</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Timon</td>\n",
       "      <td>None</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              charname                                        description  \\\n",
       "0               Antony                                  (Marcus Antonius)   \n",
       "1            Cleopatra                                     queen of Egypt   \n",
       "2             Falstaff                                  Sir John Falstaff   \n",
       "3   Duke of Gloucester                                brother to the King   \n",
       "4               Hamlet  son of the former king and nephew to the prese...   \n",
       "5              Henry V                            Prince, King of England   \n",
       "6                 Iago                              Othello's ancient (?)   \n",
       "7              Othello   A noble Moor in the service of the Ventian state   \n",
       "8                 Poet                  the voice of Shakespeare's poetry   \n",
       "9          Richard III  son of Richard Plantagenet, duke of York; was ...   \n",
       "10            Rosalind                      daughter to the banished Duke   \n",
       "11               Timon                                               None   \n",
       "\n",
       "    speechcount  \n",
       "0         253.0  \n",
       "1         204.0  \n",
       "2         471.0  \n",
       "3         285.0  \n",
       "4         358.0  \n",
       "5         377.0  \n",
       "6         272.0  \n",
       "7         274.0  \n",
       "8         733.0  \n",
       "9         246.0  \n",
       "10        201.0  \n",
       "11        210.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myquery = '''\n",
    "SELECT charname, description, speechcount\n",
    "FROM characters\n",
    "WHERE speechcount > 200\n",
    "'''\n",
    "pd.read_sql_query(myquery, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbserver.commit()   \n",
    "dbserver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part c\n",
    "Use the `dotenv` package to import your PostgreSQL database password into your Python environment (don't expose this password in your code). Then use this password to initialize a new Shakespeare database using PostgreSQL and the `psycopg` package. (For PostgreSQL, you will need to set the `.autocommit` attribute of Python variable that connects to the PostgreSQL server to `True`, or you will receive cryptic errors.)\n",
    "\n",
    "Next, use the `create_engine()` method from `sqlalchemy` and the `pd.to_sql()` method to add the five Shakespeare dataframes to this database (don't worry if a negative number is displayed. This is a known issue with PostgreSQL in Python but is not indicative of a problem). Then, to prove that this worked, use the `pd.read_sql_query()` method to issue the following SQL query to the database\n",
    "```\n",
    "SELECT charname, description, speechcount\n",
    "FROM characters\n",
    "WHERE speechcount > 200\n",
    "```\n",
    "Finally, after running the query, use the `.commit()` and `.close()` methods on the Python variable containing the database connection to save your changes and prevent further changes.\n",
    "\n",
    "(If you see an error like `ObjectInUse: database \"shakespeare\" is being accessed by other users DETAIL:  There is 1 other session using the database.`, go to the terminal, type Control+C, then `docker compose down`, then `docker compose up`, then try again.)\n",
    "\n",
    "[8 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbserver = psycopg.connect(\n",
    "    user='postgres', \n",
    "    password=POSTGRES_PASSWORD, \n",
    "    host='localhost',\n",
    "    port = '5432'\n",
    ")\n",
    "dbserver.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = dbserver.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cursor.execute(\"CREATE DATABASE shakespeare\")\n",
    "except:\n",
    "    cursor.execute(\"DROP DATABASE shakespeare\")\n",
    "    cursor.execute(\"CREATE DATABASE shakespeare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('postgres',), ('shakespeare',), ('template1',), ('template0',)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"SELECT datname FROM pg_database\")\n",
    "databases = cursor.fetchall()\n",
    "databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql+psycopg://postgres:***@localhost:5432/shakespeare)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbms = 'postgresql'\n",
    "package = 'psycopg'\n",
    "user = 'postgres'\n",
    "password = POSTGRES_PASSWORD\n",
    "host = 'localhost'\n",
    "port = '5432'\n",
    "db = 'shakespeare'\n",
    "\n",
    "engine = create_engine(f\"{dbms}+{package}://{user}:{password}@{host}:{port}/{db}\")\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "works.to_sql(\"works\", con = engine,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "characters.to_sql(\"characters\", con = engine,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "chapters.to_sql(\"chapters\", con = engine,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "paragraphs.to_sql(\"paragraphs\", con = engine,  index=False, chunksize=1000, if_exists=\"replace\")\n",
    "charworks.to_sql(\"charworks\", con = engine,  index=False, chunksize=1000, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charname</th>\n",
       "      <th>description</th>\n",
       "      <th>speechcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Antony</td>\n",
       "      <td>(Marcus Antonius)</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>queen of Egypt</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Falstaff</td>\n",
       "      <td>Sir John Falstaff</td>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Duke of Gloucester</td>\n",
       "      <td>brother to the King</td>\n",
       "      <td>285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hamlet</td>\n",
       "      <td>son of the former king and nephew to the prese...</td>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Henry V</td>\n",
       "      <td>Prince, King of England</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iago</td>\n",
       "      <td>Othello's ancient (?)</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Othello</td>\n",
       "      <td>A noble Moor in the service of the Ventian state</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Poet</td>\n",
       "      <td>the voice of Shakespeare's poetry</td>\n",
       "      <td>733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Richard III</td>\n",
       "      <td>son of Richard Plantagenet, duke of York; was ...</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rosalind</td>\n",
       "      <td>daughter to the banished Duke</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Timon</td>\n",
       "      <td>None</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              charname                                        description  \\\n",
       "0               Antony                                  (Marcus Antonius)   \n",
       "1            Cleopatra                                     queen of Egypt   \n",
       "2             Falstaff                                  Sir John Falstaff   \n",
       "3   Duke of Gloucester                                brother to the King   \n",
       "4               Hamlet  son of the former king and nephew to the prese...   \n",
       "5              Henry V                            Prince, King of England   \n",
       "6                 Iago                              Othello's ancient (?)   \n",
       "7              Othello   A noble Moor in the service of the Ventian state   \n",
       "8                 Poet                  the voice of Shakespeare's poetry   \n",
       "9          Richard III  son of Richard Plantagenet, duke of York; was ...   \n",
       "10            Rosalind                      daughter to the banished Duke   \n",
       "11               Timon                                               None   \n",
       "\n",
       "    speechcount  \n",
       "0         253.0  \n",
       "1         204.0  \n",
       "2         471.0  \n",
       "3         285.0  \n",
       "4         358.0  \n",
       "5         377.0  \n",
       "6         272.0  \n",
       "7         274.0  \n",
       "8         733.0  \n",
       "9         246.0  \n",
       "10        201.0  \n",
       "11        210.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myquery = '''\n",
    "SELECT charname, description, speechcount\n",
    "FROM characters\n",
    "WHERE speechcount > 200\n",
    "'''\n",
    "pd.read_sql_query(myquery, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbserver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "[Colin Mitchell](http://muffinlabs.com/) is a web-developer and artist who has a bunch of cool projects that play with what data can do on the internet. One of his projects is [Today in History](https://history.muffinlabs.com/), which provides an API to access all the Wikipedia pages for historical events that happened on this day in JSON format. The records in this JSON are stored in the `['data']['events']` path. Here's the first listing for today (the day I ran this code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year': '456',\n",
       " 'text': 'Ricimer defeats Avitus at Piacenza and becomes master of the Western Roman Empire.',\n",
       " 'html': '456 - <a href=\"https://wikipedia.org/wiki/Ricimer\" title=\"Ricimer\">Ricimer</a> defeats Avitus at Piacenza and becomes master of the Western Roman Empire.',\n",
       " 'no_year_html': '<a href=\"https://wikipedia.org/wiki/Ricimer\" title=\"Ricimer\">Ricimer</a> defeats Avitus at Piacenza and becomes master of the Western Roman Empire.',\n",
       " 'links': [{'title': 'Ricimer', 'link': 'https://wikipedia.org/wiki/Ricimer'}]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = requests.get(\"https://history.muffinlabs.com/date\")\n",
    "history_json = json.loads(history.text)\n",
    "events = history_json['data']['Events']\n",
    "events[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the count of total events for the day I ran this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, you will use MongoDB and the `pymongo` package to create a local document store NoSQL database containing these historical events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a\n",
    "First, check that your work for problem 1 is still running without error. If so, then you have a MongoDB server running inside a Docker container. \n",
    "\n",
    "Use `pymongo` to connect to the local MongoDB client, create a database named \"history\" and a collection within that database named \"today\". Because you will probably be running this code several times as you work, debugging as you go along, it's useful write code that deletes any existing \"today\" collections before creating a new \"today\" collection.\n",
    "\n",
    "[4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_user = os.getenv('MONGO_INITDB_ROOT_USERNAME')\n",
    "mongo_password = os.getenv('MONGO_INITDB_ROOT_PASSWORD')\n",
    "host = 'localhost'\n",
    "port = 27017\n",
    "myclient = pymongo.MongoClient(f\"mongodb://{mongo_user}:{mongo_password}@{host}:{port}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = myclient[\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = history.list_collection_names()\n",
    "if \"today\" in collist:\n",
    "  history.today.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = history[\"today\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part b\n",
    "Insert all of the records in `events` into this collection. [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventstoday = today.insert_many(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.today.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c\n",
    "Issue the following query to find all of the records whose text contain the word \"Virginia\":\n",
    "```\n",
    "query = {\n",
    "    \"text\":{\n",
    "        \"$regex\": 'England'\n",
    "    }\n",
    "}\n",
    "```\n",
    "If there are no results that contain the word \"England\", choose a different word like \"China\" or \"war\". Display the count of the number of documents that match this query, display the output of the query, and generate a JSON formatted variable containing the output. [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {\n",
    "    \"text\":{\n",
    "        \"$regex\": 'Virginia'\n",
    "    }\n",
    "}\n",
    "vatoday = history.today.find(query) \n",
    "history.today.count_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mongo_query(collection, row_query={}, col_query={}):\n",
    "    find = collection.find(row_query, col_query)\n",
    "    find_dump = dumps(find)\n",
    "    find_loads = loads(find_dump)\n",
    "    return find_loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('68f06523f81500e0df9e452a'),\n",
       "  'year': '1859',\n",
       "  'text': 'Origins of the American Civil War: Abolitionist John Brown and his supporters launch a raid on Harpers Ferry, Virginia (now West Virginia).',\n",
       "  'html': '1859 - <a href=\"https://wikipedia.org/wiki/Origins_of_the_American_Civil_War\" title=\"Origins of the American Civil War\">Origins of the American Civil War</a>: <a href=\"https://wikipedia.org/wiki/Abolitionism_in_the_United_States\" title=\"Abolitionism in the United States\">Abolitionist</a> <a href=\"https://wikipedia.org/wiki/John_Brown_(abolitionist)\" title=\"John Brown (abolitionist)\">John Brown</a> and his supporters <a href=\"https://wikipedia.org/wiki/John_Brown%27s_raid_on_Harpers_Ferry\" title=\"John Brown\\'s raid on Harpers Ferry\">launch a raid</a> on <a href=\"https://wikipedia.org/wiki/Harpers_Ferry,_Virginia\" class=\"mw-redirect\" title=\"Harpers Ferry, Virginia\">Harpers Ferry, Virginia</a> (now West Virginia).',\n",
       "  'no_year_html': '<a href=\"https://wikipedia.org/wiki/Origins_of_the_American_Civil_War\" title=\"Origins of the American Civil War\">Origins of the American Civil War</a>: <a href=\"https://wikipedia.org/wiki/Abolitionism_in_the_United_States\" title=\"Abolitionism in the United States\">Abolitionist</a> <a href=\"https://wikipedia.org/wiki/John_Brown_(abolitionist)\" title=\"John Brown (abolitionist)\">John Brown</a> and his supporters <a href=\"https://wikipedia.org/wiki/John_Brown%27s_raid_on_Harpers_Ferry\" title=\"John Brown\\'s raid on Harpers Ferry\">launch a raid</a> on <a href=\"https://wikipedia.org/wiki/Harpers_Ferry,_Virginia\" class=\"mw-redirect\" title=\"Harpers Ferry, Virginia\">Harpers Ferry, Virginia</a> (now West Virginia).',\n",
       "  'links': [{'title': 'Origins of the American Civil War',\n",
       "    'link': 'https://wikipedia.org/wiki/Origins_of_the_American_Civil_War'},\n",
       "   {'title': 'Abolitionism in the United States',\n",
       "    'link': 'https://wikipedia.org/wiki/Abolitionism_in_the_United_States'},\n",
       "   {'title': 'John Brown (abolitionist)',\n",
       "    'link': 'https://wikipedia.org/wiki/John_Brown_(abolitionist)'},\n",
       "   {'title': \"John Brown's raid on Harpers Ferry\",\n",
       "    'link': 'https://wikipedia.org/wiki/John_Brown%27s_raid_on_Harpers_Ferry'},\n",
       "   {'title': 'Harpers Ferry, Virginia',\n",
       "    'link': 'https://wikipedia.org/wiki/Harpers_Ferry,_Virginia'}]}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results =mongo_query(history.today, \n",
    "            row_query={\"text\": {\"$regex\": \"Virginia\"}}, \n",
    "            col_query={})\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "Once you are finished working with databases, clear up the space on your computer by going to the terminal that you used to launch the Docker containers, press CONTROL + C on your keyboard to stop the containers, then type `docker compose down` to disconnect the volumes and networks. It's a good idea to make a practice out of doing these steps when you finish working with databases.\n",
    "\n",
    "This problem isn't graded, and no need to write anything. But please do this anyway."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds6001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
